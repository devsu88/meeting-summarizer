# ğŸ¯ Meeting Summarizer

Una **web app interattiva** con **Gradio** che permette di caricare una trascrizione o un file audio/video di un meeting e genera automaticamente una **sintesi completa**, un elenco di **topic** e **parole chiave**.

## ğŸš€ FunzionalitÃ 

- ğŸ“ **Upload multipli**: Supporta file `.txt`, `.pdf`, `.docx`, `.mp3`, `.wav`, `.m4a`, `.flac`, `.ogg`
- ğŸ¤ **Trascrizione automatica**: Usa `whisper-tiny` per trascrivere file audio
- ğŸ¤– **Analisi intelligente**: GPT-4o-mini per estrarre sintesi, topic e keywords
- ğŸ“„ **PDF professionale**: Genera documenti PDF ben formattati
- ğŸ’¾ **Persistenza dati**: Salvataggio su Hugging Face Datasets
- ğŸŒ **Deploy facile**: Pronto per Hugging Face Spaces

## ğŸ› ï¸ Tecnologie

- **Framework UI**: [Gradio](https://gradio.app/)
- **LLM**: `gpt-4o-mini` tramite API OpenAI
- **Trascrizione**: `openai/whisper-tiny` (ottimizzato per CPU)
- **Estrazione testo**: `pypdf2` e `python-docx`
- **Generazione PDF**: `reportlab`
- **Persistenza**: Hugging Face Datasets
- **Audio processing**: `librosa` per elaborazione audio
- **Accelerazione**: `accelerate` per ottimizzazioni
- **Linguaggio**: Python 3.10

## ğŸ“¦ Installazione

### Locale

```bash
# Clona il repository
git clone https://github.com/your-username/meeting-summarizer.git
cd meeting-summarizer

# Installa dipendenze
pip install -r requirements.txt

# Avvia l'applicazione
python app.py
```

### Hugging Face Spaces

1. **Fork** questo repository
2. Crea un nuovo **Space** su [Hugging Face](https://huggingface.co/spaces)
3. Seleziona **Gradio** come SDK
4. Collega il repository forked
5. Configura le variabili d'ambiente (vedi sezione Configurazione)

## âš™ï¸ Configurazione

### Variabili d'Ambiente

Per il deploy su Hugging Face Spaces, configura:

```bash
# Obbligatorio
OPENAI_API_KEY=your_openai_api_key_here

# Opzionale (per persistenza dati)
HF_TOKEN=your_huggingface_token_here
```

### Configurazione Locale

Crea un file `.env` nella root del progetto:

```bash
OPENAI_API_KEY=your_openai_api_key_here
HF_TOKEN=your_huggingface_token_here
```

## ğŸ¯ Utilizzo

1. **Carica un file** di meeting (audio o documento)
2. **Inserisci la chiave API OpenAI** (richiesta)
3. **Inserisci il token HF** (opzionale, per salvare i dati)
4. **Clicca "Analizza Meeting"**
5. **Visualizza i risultati** e scarica il PDF

### Formati Supportati

#### ğŸµ File Audio
- MP3, WAV, M4A, FLAC, OGG
- Trascrizione automatica con Whisper

#### ğŸ“„ Documenti
- PDF, DOCX, TXT
- Estrazione testo automatica

## ğŸ“Š Struttura Dati

I meeting vengono salvati su Hugging Face Datasets con questa struttura:

```json
{
  "id": "uuid",
  "file_name": "nome_file_originale",
  "meeting_date": "YYYY-MM-DD",
  "transcription": "testo completo del meeting",
  "summary": "testo della sintesi",
  "topics": ["tema1", "tema2", ...],
  "keywords": ["parola1", "parola2", ...],
  "created_at": "timestamp"
}
```

## ğŸ—ï¸ Architettura

```
meeting-summarizer/
â”œâ”€â”€ app.py                 # Applicazione Gradio principale
â”œâ”€â”€ requirements.txt       # Dipendenze Python
â”œâ”€â”€ README.md             # Documentazione
â”œâ”€â”€ .gitignore            # File da ignorare
â””â”€â”€ utils/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ text_extraction.py   # Estrazione testo da PDF/DOCX/TXT
    â”œâ”€â”€ transcription.py     # Trascrizione audio con Whisper
    â”œâ”€â”€ llm_analysis.py       # Analisi con GPT-4o-mini
    â”œâ”€â”€ pdf_generator.py     # Generazione PDF output
    â””â”€â”€ data_persistence.py # Salvataggio su HF Datasets
```

## ğŸ”§ Sviluppo

### Setup Ambiente di Sviluppo

```bash
# Crea ambiente virtuale
python -m venv venv
source venv/bin/activate  # Linux/Mac
# oppure
venv\Scripts\activate     # Windows

# Installa dipendenze
pip install -r requirements.txt

# Avvia in modalitÃ  sviluppo
python app.py
```

### Test

```bash
# Test estrazione testo
python -c "from utils.text_extraction import extract_text; print(extract_text('test.pdf'))"

# Test trascrizione
python -c "from utils.transcription import transcribe_audio; print(transcribe_audio('test.mp3'))"
```

## ğŸ“ Note Tecniche

- **Whisper**: Usa `openai/whisper-tiny` per velocitÃ  su CPU
- **Lingua**: Prompt ottimizzati per italiano
- **Persistenza**: HF Datasets garantisce storage permanente
- **Sicurezza**: API keys gestite tramite variabili d'ambiente
- **CompatibilitÃ **: Python 3.10, ottimizzato per CPU only

## ğŸ¤ Contributi

1. Fork il progetto
2. Crea un branch per la tua feature (`git checkout -b feature/AmazingFeature`)
3. Commit le modifiche (`git commit -m 'Add some AmazingFeature'`)
4. Push al branch (`git push origin feature/AmazingFeature`)
5. Apri una Pull Request

## ğŸ“„ Licenza

Distribuito sotto licenza MIT. Vedi `LICENSE` per maggiori informazioni.

## ğŸ†˜ Supporto

- ğŸ“§ **Email**: support@meeting-summarizer.com
- ğŸ› **Issues**: [GitHub Issues](https://github.com/your-username/meeting-summarizer/issues)
- ğŸ“– **Documentazione**: [Wiki](https://github.com/your-username/meeting-summarizer/wiki)

## ğŸ™ Ringraziamenti

- [Gradio](https://gradio.app/) per il framework UI
- [OpenAI](https://openai.com/) per GPT-4o-mini e Whisper
- [Hugging Face](https://huggingface.co/) per i modelli e l'hosting
- [ReportLab](https://www.reportlab.com/) per la generazione PDF

---

**Sviluppato con â¤ï¸ per semplificare l'analisi dei meeting**